{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day2----一些核心的机器学习算法\n",
    "在这个部分，我们会试着学习几种核心的算法，并加以不同的例子，数据来进行实践：\n",
    "- Linear regression 线性回归\n",
    "- Classification 分类\n",
    "- Clustering 聚类\n",
    "- Hidden Markov Model 隐藏马尔可夫模型\n",
    "\n",
    "## Linear Regression 线性回归\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = [1,2,2.5,3,4]\n",
    "y = [1,4,7,9,15]\n",
    "plt.plot(x,y,'ro')  # 用 x y 来画点，'ro'是 参数 红色圆点\n",
    "plt.axis([0,6,0,20]) # 指定 x y 轴数据的范围"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，上面的点具有线性相关（ linear coorespondence ）\n",
    "具有 **y = mx +b**的 近似\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y,'ro')\n",
    "plt.axis([0,6,0,20])\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x,y,1))(np.unique(x)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画出最佳线性拟合 （ line of best fit ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup and import 设置及导入\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x  # 只有使用google colab 的时候需要这个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v2.feature_column as fc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data 数据的导入\n",
    "这里使用的是泰坦尼克号数据集\n",
    "它会包含乘客的一些信息：性别、年龄、船舱等级..... 以及最后是否存活的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "\n",
    "# 使用 pd 来读取 csv 文件\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
    "# head()会返回最开始的5个entry\n",
    "print(dftrain.head())\n",
    "\n",
    "# pop 会把一个元素给分离出来，也就是这里的survived，这个东西会被用来当作label \n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')\n",
    "\n",
    "print(dftrain.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.age.hist(bins=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training vs Testing Data 训练数据和测试数据\n",
    "传统来说，机器学习需要两组数据，训练集 （training data） 和 测试集（testing data） \n",
    "\n",
    "使用训练集来 feed 我们的模型，再用测试集来评估它的准确度。\n",
    "\n",
    "再测试的时候，必须使用它之前没有见过的数据才行，所以我们需要测试集\n",
    "\n",
    "### Feature Column 特征列\n",
    "数据有两种类型： 数量型（Numeric） 和 种类型 （Categorical）\n",
    "\n",
    "但是在训练的时候，我们需要把种类型也转换成数量型（eg. male =1, female =2）\n",
    "\n",
    "TensorFlow 可以为我们代劳：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "                       'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "feature_columns = [] # 创建一个空的list\n",
    "# 遍历 种类型 的 特征\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "  # 获取 种类型 的所有不同种类有哪些\n",
    "  vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n",
    "  # 之后再把这些种类 append 到它的后面, 调用某个函数处理\n",
    "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "  # 对应数量型的特征，不需要 vocabulary，直接调用另一个函数\n",
    "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain[\"sex\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Process 训练过程\n",
    "显然，训练模型就是一个把数据喂（feed）给模型的过程。 在这里，泰坦尼克号的数据集只有600 多个数据，也许可以直接全部放到你的 RAM 上面。\n",
    "\n",
    "但是如果数据很庞大，没有RAM能处理这样子大的数据，或者也会极度缓慢。\n",
    "\n",
    "所以，通常的办法是分批次喂。 （batch）\n",
    "\n",
    "在这里，我们一次喂32个数据 （batch-size）\n",
    "\n",
    "We will actually feed these batches to our model multiple times acccording to the number of **epochs** （最大训练数）\n",
    "\n",
    "Epochs is simply one stream of data of our entire dataset. \n",
    "\n",
    "The number of epochs we defineis the amount of times our model will see the entire dataset.\n",
    "\n",
    "一个epochs 就是数据库的全部数据被模型读取一遍。\n",
    "epochs 定义了我们的模型会读取整个数据库数据 多少次\n",
    "也就是同一个数据，会被模型读取几遍 \n",
    "\n",
    "每一次epochs， 改变数据输入的顺序，也许会慢慢得到更加准确的结果。\n",
    "\n",
    "但是，如果次数太大，可能会有过拟合（overfitting）的情况。\n",
    "这意味着模型开始记住这些点的位置。\n",
    "\n",
    "在这个数据集上，它预测得很好，但是对于崭新的数据，预测效果不佳\n",
    "\n",
    "### Input Function 输入方程\n",
    "TensorFlow 模型 要求输入的模型必须是 tf.data.Dataset 类的 object。 所以我们需要一个input function 把现在的 pandas dataframe 转化成 那种 object\n",
    "\n",
    "以下是一个例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "  # 这个函数，返回一个input 函数\n",
    "  def input_function():  # 定义一个 inner function，这个就是我们需要的 input function\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(1000)  # randomize order of data\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
    "    return ds  # return a batch of the dataset\n",
    "  return input_function  # return a function object for use\n",
    "\n",
    "# 给训练集和测试集分别创造 输入函数 \n",
    "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model 建立模型\n",
    "\n",
    "下面的linear_est 就是我们的模型本体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "# 把前面定义的 feature_columns 传递给这个函数作为参数\n",
    "# We create a linear estimtor by passing the feature columns we created earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model 训练模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_est.train(train_input_fn)  # 把训练集的 输入函数 传递给模型的 train（）函数\n",
    "result = linear_est.evaluate(eval_input_fn)  # 把测试集的 输入函数 传递给 模型的evaluate（）函数 result 就是我们的结果\n",
    "\n",
    "clear_output()  # clears console output\n",
    "print(result['accuracy'])  # 打印结果的accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 崩溃了，搞了半天 发现在本地的环境里面就是不能运行 tensorflow-estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
